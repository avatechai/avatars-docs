---
title: "Avatar Customization"
---

## Create avatars

You can generate avatars from our [labs](https://labs.avatech.ai). With the help of text-to-image AI model, you can create different avatar by only describing your imagination.

After generated your avatar, you can click the 'view code' button at the top-right corner to copy the avatarId. Then replace the avatarId inside the 'useAvatar' hook.

## Avatar refinement

We provide different services to make your own avatar comes alive:

<AccordionGroup>
  <Accordion title="Lip-sync">

    ### Basic lip-sync

    The avatars generated from our labs support real-time lip-sync based on audio provided to our sdk.

    To make your avatar start talking, you need to first initialize the sdk audio service.

    ```jsx
    const { avatarDisplay, context, audioInit } = useAvatar({
      //...
    });

    //...

    return (
      <button onClick={() => {audioInit()}}>Init</button>
    )
    ```

    <Info>
      The `audioInit()` must be called after a user gesture due to security reason restricted by web browser.
    </Info>

    Then you can make your avatar start talking by calling the `play()` function with the source of the audio file.

    ```jsx
    const { avatarDisplay, context, audioInit } = useAvatar({
      //...
    });

    //...

    return (
      <button onClick={() => {
        context.current?.client?.play('your audio file src')
        }}
      >
      Talk
      </button>
    )
    ```

    ### Advance Audio Customization

    If you want to handle the audio part yourself (For example, to adjust volume or adding eventlistener), you can pass different options into the function `audioInit()`:

    | Field            | type             |
    | ---------------- | ---------------- |
    | `audioContext`   | AudioContext     |
    | `audioelement`   | HTMLAudioElement |
    | `audioSourceNode`| AudioNode        |

    ```jsx
    const { avatarDisplay, context, audioInit } = useAvatar({
      //...
    });

    const audioElement = new Audio()
    const audioContext = new (window.AudioContext || window.webkitAudioContext)()
    const audioSourceNode = audioContext.createMediaElementSource(audioElement)

    //...

    return (
      <button
        onClick={() => {audioInit({
          audioElement: audioElement
          audioContext: audioContext
          audioSourceNode: audioSourceNode
        })
        }}
      >
       Init
      </button>
    )
    ```

    Once the audioElement start playing, the avatar will start lip-sync based on the audioElement.

  </Accordion>

  <Accordion title="Expression">
    you can set the avatar expression by calling the function below:
    
    ```jsx
    context.current.client.setAvatarEmotion('your emotion')
    ```

    you can get all the emotion avatar supported by calling the function below:
    ```jsx
    context.current.client.getAvatarAllEmotion('your emotion')
    ```

  </Accordion>
</AccordionGroup>
